"""ë“€ì–¼ ëª¨ë¸ ì½”ë“œ ì„¤ëª… ì„œë¹„ìŠ¤ë¥¼ ìœ„í•œ FastAPI ì§„ì…ì ."""

from fastapi import FastAPI
from pydantic import BaseModel, Field
from typing import Optional, List
from google import genai
from dotenv import load_dotenv
import os

from gemini import generate_content_gemini, StructuredResponse

load_dotenv()
gemini_api_key = os.getenv("GEMINI_API_KEY")

app = FastAPI(
    title="Dash AI Server",
    description="ì•Œê³ ë¦¬ì¦˜ ì½”ë“œ ë¶„ì„ AI ì„œë²„",
    version="1.0.0"
)


class CodeReviewRequest(BaseModel):
    """ì½”ë“œ ë¦¬ë·° ìš”ì²­ ìŠ¤í‚¤ë§ˆ"""
    code: str
    language: Optional[str] = "java"
    problemNumber: Optional[str] = None


class UserContext(BaseModel):
    """ì‚¬ìš©ì ì»¨í…ìŠ¤íŠ¸"""
    weakTags: List[str] = []
    solvedCount: int = 0
    tier: int = 0
    tierName: str = "Unrated"


class HintRequest(BaseModel):
    """íŒíŠ¸ ìš”ì²­ ìŠ¤í‚¤ë§ˆ"""
    problemNumber: str
    problemTitle: Optional[str] = None
    level: int = Field(ge=1, le=3, default=1)  # 1: ìœ í˜•, 2: ì ‘ê·¼ë²•, 3: ìƒì„¸
    userContext: Optional[UserContext] = None


class HintResponse(BaseModel):
    """íŒíŠ¸ ì‘ë‹µ ìŠ¤í‚¤ë§ˆ"""
    level: int
    hint: str
    encouragement: str
    relatedConcepts: List[str]
    nextStepSuggestion: str


@app.get("/")
def read_root():
    """ìƒíƒœ í™•ì¸ ì—”ë“œí¬ì¸íŠ¸."""
    return {"status": "ok", "service": "Dash AI Server"}


@app.post("/review", response_model=StructuredResponse)
async def review_code(request: CodeReviewRequest):
    """ì½”ë“œ ë¶„ì„ ì—”ë“œí¬ì¸íŠ¸ - Dash Backendì—ì„œ í˜¸ì¶œ"""
    result = generate_content_gemini(request.code)
    return result


@app.post("/hint", response_model=HintResponse)
async def generate_hint(request: HintRequest):
    """íŒíŠ¸ ìƒì„± ì—”ë“œí¬ì¸íŠ¸ - ë ˆë²¨ë³„ ë§ì¶¤ íŒíŠ¸ ì œê³µ"""
    
    # ë ˆë²¨ë³„ í”„ë¡¬í”„íŠ¸ êµ¬ì„±
    level_prompts = {
        1: "í•µì‹¬ ì•Œê³ ë¦¬ì¦˜ ìœ í˜•ë§Œ ê°„ë‹¨íˆ ì•Œë ¤ì£¼ì„¸ìš”. êµ¬ì²´ì ì¸ í’€ì´ëŠ” ì–¸ê¸‰í•˜ì§€ ë§ˆì„¸ìš”.",
        2: "êµ¬ì²´ì ì¸ ì ‘ê·¼ë²•ê³¼ ì „ëµì„ ì„¤ëª…í•´ì£¼ì„¸ìš”. í•˜ì§€ë§Œ ì½”ë“œë‚˜ ìˆ˜ë„ì½”ë“œëŠ” ì œê³µí•˜ì§€ ë§ˆì„¸ìš”.",
        3: "ìƒì„¸í•œ í’€ì´ ê°€ì´ë“œì™€ ìˆ˜ë„ì½”ë“œë¥¼ ì œê³µí•´ì£¼ì„¸ìš”."
    }
    
    weak_tags_str = ", ".join(request.userContext.weakTags) if request.userContext and request.userContext.weakTags else "ì—†ìŒ"
    tier_info = f"{request.userContext.tierName} (Tier {request.userContext.tier})" if request.userContext else "ì •ë³´ ì—†ìŒ"
    
    prompt = f"""ë‹¹ì‹ ì€ ì•Œê³ ë¦¬ì¦˜ íŠœí„°ì…ë‹ˆë‹¤. í•™ìƒì—ê²Œ ë¬¸ì œì— ëŒ€í•œ íŒíŠ¸ë¥¼ ì œê³µí•©ë‹ˆë‹¤.

ë¬¸ì œ ë²ˆí˜¸: {request.problemNumber}
ë¬¸ì œ ì œëª©: {request.problemTitle or "ì•Œ ìˆ˜ ì—†ìŒ"}
íŒíŠ¸ ë ˆë²¨: {request.level}

í•™ìƒ ì •ë³´:
- í‹°ì–´: {tier_info}
- í‘¼ ë¬¸ì œ ìˆ˜: {request.userContext.solvedCount if request.userContext else 0}
- ì•½ì  íƒœê·¸: {weak_tags_str}

ìš”ì²­: {level_prompts[request.level]}

ì‘ë‹µ í˜•ì‹ (JSON):
{{
    "level": {request.level},
    "hint": "íŒíŠ¸ ë‚´ìš©",
    "encouragement": "ê²©ë ¤ ë©”ì‹œì§€",
    "relatedConcepts": ["ê´€ë ¨ ê°œë…1", "ê´€ë ¨ ê°œë…2"],
    "nextStepSuggestion": "ì¶”ê°€ í•™ìŠµ ì¶”ì²œ"
}}
"""
    
    client = genai.Client(api_key=gemini_api_key)
    response = client.models.generate_content(
        model="gemini-2.5-flash",
        contents=prompt,
        config={
            "response_mime_type": "application/json",
            "response_json_schema": HintResponse.model_json_schema(),
        },
    )
    
    result = HintResponse.model_validate_json(response.text)
    return result


# ---- Learning Path Endpoint ----

class TagInfo(BaseModel):
    """íƒœê·¸ ì •ë³´"""
    tagKey: str
    solved: int
    total: int


class ClassInfo(BaseModel):
    """í´ë˜ìŠ¤ ì •ë³´"""
    classNumber: int
    essentialSolved: int
    essentials: int
    completionRate: float


class LearningPathRequest(BaseModel):
    """í•™ìŠµ ê²½ë¡œ ìš”ì²­ ìŠ¤í‚¤ë§ˆ"""
    currentLevel: str
    nextGoal: str
    weaknessTags: List[TagInfo] = []
    strengthTags: List[TagInfo] = []
    classProgress: List[ClassInfo] = []
    solvedCount: int = 0
    balanceType: Optional[str] = "BALANCED"
    growthTrend: Optional[str] = "STABLE"


class LearningPhase(BaseModel):
    """í•™ìŠµ ë‹¨ê³„"""
    priority: int
    title: str
    description: str
    estimatedTime: str
    actionItems: List[str]


class LearningPathResponse(BaseModel):
    """í•™ìŠµ ê²½ë¡œ ì‘ë‹µ ìŠ¤í‚¤ë§ˆ"""
    overallAssessment: str
    keyStrength: str
    primaryWeakness: str
    personalizedAdvice: str
    phases: List[LearningPhase]
    motivationalMessage: str


@app.post("/learning-path", response_model=LearningPathResponse)
async def generate_learning_path(request: LearningPathRequest):
    """AI ê°œì¸í™” í•™ìŠµ ê²½ë¡œ ìƒì„± ì—”ë“œí¬ì¸íŠ¸"""
    
    # ì•½ì /ê°•ì  ì •ë³´ í¬ë§·
    weakness_str = "\n".join([f"  - {t.tagKey}: {t.solved}/{t.total}ë¬¸ì œ" for t in request.weaknessTags]) or "  ì—†ìŒ"
    strength_str = "\n".join([f"  - {t.tagKey}: {t.solved}/{t.total}ë¬¸ì œ" for t in request.strengthTags]) or "  ì—†ìŒ"
    class_str = "\n".join([f"  - Class {c.classNumber}: {c.essentialSolved}/{c.essentials} ({c.completionRate:.0f}%)" 
                          for c in request.classProgress]) or "  ì—†ìŒ"
    
    prompt = f"""ë‹¹ì‹ ì€ ì•Œê³ ë¦¬ì¦˜ í•™ìŠµ ì½”ì¹˜ì…ë‹ˆë‹¤. ì‚¬ìš©ìì˜ ë¶„ì„ ë°ì´í„°ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ê°œì¸í™”ëœ í•™ìŠµ ê²½ë¡œë¥¼ ì œì•ˆí•´ì£¼ì„¸ìš”.

## ì‚¬ìš©ì í˜„í™©
- í˜„ì¬ ë ˆë²¨: {request.currentLevel}
- ë‹¤ìŒ ëª©í‘œ: {request.nextGoal}
- ì´ í‘¼ ë¬¸ì œ: {request.solvedCount}ë¬¸ì œ
- í•™ìŠµ ìœ í˜•: {request.balanceType}
- ì„±ì¥ ì¶”ì„¸: {request.growthTrend}

## ì•½ì  íƒœê·¸
{weakness_str}

## ê°•ì  íƒœê·¸
{strength_str}

## í´ë˜ìŠ¤ ì§„í–‰ë„
{class_str}

ìœ„ ì •ë³´ë¥¼ ë¶„ì„í•˜ì—¬ ë‹¤ìŒ í˜•ì‹ì˜ JSONìœ¼ë¡œ ê°œì¸í™”ëœ í•™ìŠµ ê²½ë¡œë¥¼ ì œì•ˆí•´ì£¼ì„¸ìš”.
ê° ë‹¨ê³„ëŠ” êµ¬ì²´ì ì´ê³  ì‹¤ì²œ ê°€ëŠ¥í•´ì•¼ í•©ë‹ˆë‹¤.

{{
    "overallAssessment": "í˜„ì¬ ìƒíƒœì— ëŒ€í•œ ì¢…í•© í‰ê°€",
    "keyStrength": "ê°€ì¥ í° ê°•ì ",
    "primaryWeakness": "ê°€ì¥ ì‹œê¸‰í•œ ì•½ì ",
    "personalizedAdvice": "ê°œì¸í™”ëœ ì¡°ì–¸ (2-3ë¬¸ì¥)",
    "phases": [
        {{
            "priority": 1,
            "title": "ì²« ë²ˆì§¸ ë‹¨ê³„ ì œëª©",
            "description": "ìƒì„¸ ì„¤ëª…",
            "estimatedTime": "ì˜ˆìƒ ì†Œìš” ì‹œê°„ (ì˜ˆ: 1-2ì£¼)",
            "actionItems": ["êµ¬ì²´ì  ì‹¤ì²œ í•­ëª© 1", "êµ¬ì²´ì  ì‹¤ì²œ í•­ëª© 2"]
        }}
    ],
    "motivationalMessage": "ë™ê¸°ë¶€ì—¬ ë©”ì‹œì§€"
}}
"""
    
    client = genai.Client(api_key=gemini_api_key)
    response = client.models.generate_content(
        model="gemini-2.5-flash",
        contents=prompt,
        config={
            "response_mime_type": "application/json",
            "response_json_schema": LearningPathResponse.model_json_schema(),
        },
    )
    
    result = LearningPathResponse.model_validate_json(response.text)
    return result


# ---- Coding Style Analysis Endpoint ----

class CodeSample(BaseModel):
    """ì½”ë“œ ìƒ˜í”Œ"""
    code: str
    language: str = "java"
    problemNumber: Optional[str] = None
    runtimeMs: int = 0
    memoryKb: int = 0


class UserStats(BaseModel):
    """ì‚¬ìš©ì í†µê³„"""
    totalSolved: int = 0
    avgRuntime: float = 0
    avgMemory: float = 0
    preferredTags: List[str] = []
    tier: str = "Unrated"


class CodingStyleRequest(BaseModel):
    """ì½”ë”© ìŠ¤íƒ€ì¼ ë¶„ì„ ìš”ì²­"""
    codeSamples: List[CodeSample]
    userStats: Optional[UserStats] = None


class StyleAxis(BaseModel):
    """ìŠ¤íƒ€ì¼ ì¶•"""
    axis: str
    result: str
    score: int
    leftLabel: str
    rightLabel: str
    description: str


class CodingStyleResponse(BaseModel):
    """ì½”ë”© ìŠ¤íƒ€ì¼ ë¶„ì„ ì‘ë‹µ (MBTI ìŠ¤íƒ€ì¼)"""
    mbtiCode: str
    nickname: str
    summary: str
    axes: List[StyleAxis]
    strengths: List[str]
    improvements: List[str]
    compatibleStyles: str
    advice: str


@app.post("/coding-style", response_model=CodingStyleResponse)
async def analyze_coding_style(request: CodingStyleRequest):
    """ì½”ë”© ìŠ¤íƒ€ì¼ ë¶„ì„ ì—”ë“œí¬ì¸íŠ¸ (MBTI ìŠ¤íƒ€ì¼)"""
    
    # ì½”ë“œ ìƒ˜í”Œ ìš”ì•½
    code_samples_str = "\n---\n".join([
        f"```{s.language}\n{s.code[:500]}{'...' if len(s.code) > 500 else ''}\n```\n(ëŸ°íƒ€ì„: {s.runtimeMs}ms, ë©”ëª¨ë¦¬: {s.memoryKb}KB)"
        for s in request.codeSamples[:5]
    ])
    
    stats = request.userStats or UserStats()
    
    prompt = f"""ë‹¹ì‹ ì€ ì½”ë”© ìŠ¤íƒ€ì¼ ë¶„ì„ ì „ë¬¸ê°€ì…ë‹ˆë‹¤. ì‚¬ìš©ìì˜ ì½”ë“œë¥¼ ë¶„ì„í•˜ì—¬ MBTIì²˜ëŸ¼ 4ê°€ì§€ ì¶•ìœ¼ë¡œ ì½”ë”© ìŠ¤íƒ€ì¼ì„ ë¶„ë¥˜í•´ì£¼ì„¸ìš”.

## ë¶„ì„í•  ì½”ë“œ ìƒ˜í”Œë“¤
{code_samples_str}

## ì‚¬ìš©ì í†µê³„
- ì´ í‘¼ ë¬¸ì œ: {stats.totalSolved}ë¬¸ì œ
- í‰ê·  ëŸ°íƒ€ì„: {stats.avgRuntime:.0f}ms
- í‰ê·  ë©”ëª¨ë¦¬: {stats.avgMemory:.0f}KB
- ì„ í˜¸ íƒœê·¸: {', '.join(stats.preferredTags) or 'ì—†ìŒ'}
- í‹°ì–´: {stats.tier}

## 4ê°€ì§€ ì¶• ì„¤ëª…
1. **E/I ì¶• (External/Internal)**: ì™¸í–¥ì  ì½”ë”©(ë¼ì´ë¸ŒëŸ¬ë¦¬/API ì ê·¹ ì‚¬ìš©) vs ë‚´í–¥ì  ì½”ë”©(ì§ì ‘ êµ¬í˜„ ì„ í˜¸)
2. **S/N ì¶• (Systematic/Intuitive)**: ì²´ê³„ì  ì½”ë”©(ê¼¼ê¼¼í•œ ì˜ˆì™¸ì²˜ë¦¬) vs ì§ê´€ì  ì½”ë”©(í•µì‹¬ ë¡œì§ ì§‘ì¤‘)
3. **T/F ì¶• (Time/Flow)**: ì‹œê°„ ìµœì í™” ìš°ì„  vs ê°€ë…ì„±/íë¦„ ìš°ì„ 
4. **J/P ì¶• (Judging/Perceiving)**: ê³„íšì  ì½”ë”©(êµ¬ì¡°í™”ëœ ì ‘ê·¼) vs ìœ ì—°í•œ ì½”ë”©(ì‹¤í—˜ì  ì ‘ê·¼)

ìœ„ ì½”ë“œë“¤ì„ ë¶„ì„í•˜ì—¬ ë‹¤ìŒ JSON í˜•ì‹ìœ¼ë¡œ ì‘ë‹µí•´ì£¼ì„¸ìš”:

{{
    "mbtiCode": "INTP",
    "nickname": "ë…¼ë¦¬ì  ì„¤ê³„ì",
    "summary": "ì¢…í•© ì„¤ëª… (2-3ë¬¸ì¥)",
    "axes": [
        {{
            "axis": "E/I",
            "result": "I",
            "score": 65,
            "leftLabel": "ì™¸í–¥ì  ì½”ë”©",
            "rightLabel": "ë‚´í–¥ì  ì½”ë”©",
            "description": "ì¶•ë³„ ìƒì„¸ ì„¤ëª…"
        }}
    ],
    "strengths": ["ê°•ì 1", "ê°•ì 2", "ê°•ì 3"],
    "improvements": ["ê°œì„ ì 1", "ê°œì„ ì 2"],
    "compatibleStyles": "ì˜ ë§ëŠ” ìŠ¤íƒ€ì¼ (ì˜ˆ: ENTJ)",
    "advice": "ì¡°ì–¸"
}}
"""
    
    client = genai.Client(api_key=gemini_api_key)
    response = client.models.generate_content(
        model="gemini-2.5-flash",
        contents=prompt,
        config={
            "response_mime_type": "application/json",
            "response_json_schema": CodingStyleResponse.model_json_schema(),
        },
    )
    
    result = CodingStyleResponse.model_validate_json(response.text)
    return result


# ---- Interactive Tutor Endpoint ----

class ChatMessage(BaseModel):
    """ëŒ€í™” ë©”ì‹œì§€"""
    role: str  # "user" or "assistant"
    content: str


class TutorUserContext(BaseModel):
    """íŠœí„° ì‚¬ìš©ì ì»¨í…ìŠ¤íŠ¸"""
    tier: str = "Unrated"
    solvedCount: int = 0
    recentTags: List[str] = []


class TutorChatRequest(BaseModel):
    """íŠœí„° ëŒ€í™” ìš”ì²­"""
    message: str
    problemNumber: Optional[str] = None
    code: Optional[str] = None
    history: List[ChatMessage] = []
    context: Optional[TutorUserContext] = None


class TutorChatResponse(BaseModel):
    """íŠœí„° ëŒ€í™” ì‘ë‹µ"""
    reply: str
    teachingStyle: str
    followUpQuestions: List[str]
    conceptExplanation: Optional[str] = None
    encouragement: str


@app.post("/tutor/chat", response_model=TutorChatResponse)
async def tutor_chat(request: TutorChatRequest):
    """ëŒ€í™”í˜• íŠœí„° ì±„íŒ… ì—”ë“œí¬ì¸íŠ¸ (ì†Œí¬ë¼í…ŒìŠ¤ êµìˆ˜ë²•)"""
    
    # ëŒ€í™” íˆìŠ¤í† ë¦¬ í¬ë§·
    history_str = "\n".join([
        f"{'ğŸ‘¤ í•™ìƒ' if m.role == 'user' else 'ğŸ¤– íŠœí„°'}: {m.content}"
        for m in request.history[-10:]  # ìµœê·¼ 10ê°œë§Œ
    ]) if request.history else "ì—†ìŒ"
    
    ctx = request.context or TutorUserContext()
    
    code_section = ""
    if request.code:
        code_section = f"\n## ê´€ë ¨ ì½”ë“œ\n```\n{request.code[:1000]}{'...' if len(request.code) > 1000 else ''}\n```"
    
    problem_section = f"\n## ê´€ë ¨ ë¬¸ì œ: #{request.problemNumber}" if request.problemNumber else ""
    
    prompt = f"""ë‹¹ì‹ ì€ ì¹œì ˆí•˜ê³  ê²©ë ¤í•˜ëŠ” ì•Œê³ ë¦¬ì¦˜ íŠœí„°ì…ë‹ˆë‹¤. ì†Œí¬ë¼í…ŒìŠ¤ êµìˆ˜ë²•ì„ ì‚¬ìš©í•˜ì—¬ í•™ìƒì´ ìŠ¤ìŠ¤ë¡œ ë‹µì„ ì°¾ë„ë¡ ìœ ë„í•˜ì„¸ìš”.

## ëŒ€í™” íˆìŠ¤í† ë¦¬
{history_str}

## í•™ìƒì˜ í˜„ì¬ ë©”ì‹œì§€
{request.message}
{problem_section}
{code_section}

## í•™ìƒ ì •ë³´
- í‹°ì–´: {ctx.tier}
- í‘¼ ë¬¸ì œ ìˆ˜: {ctx.solvedCount}ê°œ
- ìµœê·¼ ê´€ì‹¬ íƒœê·¸: {', '.join(ctx.recentTags) or 'ì—†ìŒ'}

## êµìˆ˜ë²• ê°€ì´ë“œë¼ì¸
1. **ì†Œí¬ë¼í…ŒìŠ¤ì‹**: ì§ì ‘ì ì¸ ë‹µ ëŒ€ì‹  ì§ˆë¬¸ì„ í†µí•´ ìƒê°ì„ ìœ ë„
2. **ê²©ë ¤**: ì–´ë ¤ì›€ì„ ê²ªì–´ë„ í¬ê¸°í•˜ì§€ ì•Šë„ë¡ ê²©ë ¤
3. **ë‹¨ê³„ì  ì ‘ê·¼**: ë³µì¡í•œ ê°œë…ì„ ì‘ì€ ë‹¨ê³„ë¡œ ë‚˜ëˆ„ì–´ ì„¤ëª…
4. **ë§ì¶¤í˜•**: í•™ìƒì˜ í‹°ì–´ì™€ ê²½í—˜ì— ë§ëŠ” ìˆ˜ì¤€ìœ¼ë¡œ ëŒ€í™”

ì‘ë‹µ í˜•ì‹ (JSON):
{{
    "reply": "íŠœí„°ì˜ ì‘ë‹µ (í•œêµ­ì–´, 200ì ì´ë‚´)",
    "teachingStyle": "socratic|direct|hint",
    "followUpQuestions": ["í›„ì† ì§ˆë¬¸ 1", "í›„ì† ì§ˆë¬¸ 2"],
    "conceptExplanation": "ê´€ë ¨ ê°œë… ì„¤ëª… (í•„ìš”ì‹œ)",
    "encouragement": "ê²©ë ¤ ë©”ì‹œì§€"
}}
"""
    
    client = genai.Client(api_key=gemini_api_key)
    response = client.models.generate_content(
        model="gemini-2.5-flash",
        contents=prompt,
        config={
            "response_mime_type": "application/json",
            "response_json_schema": TutorChatResponse.model_json_schema(),
        },
    )
    
    result = TutorChatResponse.model_validate_json(response.text)
    return result


@app.post("/generate")
async def generate_endpoint(query: str):
    """[Legacy] Gemini ë¶„ì„ê¸°ë¥¼ ì‹¤í–‰í•˜ê³  êµ¬ì¡°í™”ëœ ê²°ê³¼ë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤."""
    result = generate_content_gemini(query)
    return {"result": result}
